{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T03:13:42.779513Z",
     "start_time": "2025-04-07T03:10:21.523792Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   6 | elapsed:  1.4min remaining:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:  1.5min finished\n",
      "/opt/python/3.7/anaconda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters: {'C': 1}\n",
      "Hyperparameter Tuning Time: 172.7070 seconds\n",
      "SIMPLE LINEAR SVM CLASSIFIER\n",
      "===========================================================================\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.93      0.85      0.89     15411\n",
      "         dos       0.95      0.91      0.93     10713\n",
      "       probe       0.61      0.95      0.74      2816\n",
      "         r2l       0.26      0.32      0.29       714\n",
      "         u2r       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.87     29704\n",
      "   macro avg       0.55      0.61      0.57     29704\n",
      "weighted avg       0.89      0.87      0.87     29704\n",
      "\n",
      "Training Time: 172.7070 seconds\n",
      "Training Accuracy: 0.8647\n",
      "Testing Accuracy: 0.8696\n",
      "Precision (Weighted): 0.8893\n",
      "Recall (Weighted): 0.8696\n",
      "F1-Score (Weighted): 0.8747\n",
      "\n",
      "Confusion Matrix:\n",
      "         benign   dos  probe  r2l  u2r\n",
      "benign   13116   386   1336  572    1\n",
      "dos        546  9800    323   44    0\n",
      "probe       47    63   2686   20    0\n",
      "r2l        406    22     58  228    0\n",
      "u2r         10    13     15   12    0\n",
      "\n",
      "Overfitting/Underfitting Diagnosis:\n",
      "Good Fit.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import LinearSVC  # Switched to LinearSVC\n",
    "\n",
    "# Things that belong to strongly predictions, we just remove this\n",
    "exclusion_list = ['num_outbound_cmds', 'attack_category', 'success_pred', 'attack_type']\n",
    "\n",
    "# Define nominal and binary columns\n",
    "# numeric is calculated using above 2.\n",
    "nominal = ['protocol_type', 'service', 'flag']\n",
    "binary = ['land', 'logged_in', 'root_shell', 'su_attempted', 'is_host_login', 'is_guest_login']\n",
    "\n",
    "def define_numeric_column(data: pd.DataFrame):\n",
    "    return [col for col in data.columns if col not in nominal + binary + exclusion_list]\n",
    "\n",
    "def print_score():\n",
    "    precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    print(f\"SIMPLE LINEAR SVM CLASSIFIER\")\n",
    "    print(\"===========================================================================\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "    print(f\"Training Time: {training_time:.4f} seconds\")\n",
    "    print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (Weighted): {recall:.4f}\")\n",
    "    print(f\"F1-Score (Weighted): {f1:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\\n\", pd.DataFrame(confusion_matrix(y_test, y_test_pred), index=np.unique(y), columns=np.unique(y)))\n",
    "\n",
    "def check_fitting():\n",
    "    print(\"\\nOverfitting/Underfitting Diagnosis:\")\n",
    "    if train_accuracy > test_accuracy + 0.05:\n",
    "        print(\"Possible Overfitting.\")\n",
    "    elif train_accuracy < 0.7 and test_accuracy < 0.7:\n",
    "        print(\"Possible Underfitting.\")\n",
    "    else:\n",
    "        print(\"Good Fit.\")\n",
    "\n",
    "def preprocess_data(data: pd.DataFrame) -> tuple:\n",
    "    data = data.copy()\n",
    "    data['su_attempted'] = data['su_attempted'].replace({2: 0})\n",
    "    numeric = define_numeric_column(data)\n",
    "    return data[nominal + numeric + binary], data['attack_category']\n",
    "\n",
    "def label_encode_nominal_data(features: pd.DataFrame):\n",
    "    for col in nominal:\n",
    "        le = LabelEncoder()\n",
    "        features[col] = le.fit_transform(features[col])\n",
    "\n",
    "# Load and preprocess\n",
    "df = pd.read_csv('kdd_merged.csv')\n",
    "X, y = preprocess_data(df)\n",
    "label_encode_nominal_data(X)\n",
    "\n",
    "# Scale numeric features\n",
    "numeric_cols = define_numeric_column(df)\n",
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Pre-select features, enough of time wasted on SVN\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=20)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# GridSearchCV with LinearSVC - cause normal thing was taking a lot of time!\n",
    "dt_model = LinearSVC(random_state=42, tol=1e-3, max_iter=1000)\n",
    "param_grid = {'C': [1, 10]}\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=3, scoring='f1_weighted', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Train\n",
    "start_time = time.time()\n",
    "grid_search.fit(X_train_selected, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Best model\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "print(\"\\nBest Hyperparameters:\", grid_search.best_params_)\n",
    "print(f\"Hyperparameter Tuning Time: {training_time:.4f} seconds\")\n",
    "\n",
    "# Predict\n",
    "y_train_pred = best_dt_model.predict(X_train_selected)\n",
    "y_test_pred = best_dt_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print_score()\n",
    "check_fitting()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
