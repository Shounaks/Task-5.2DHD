{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T16:29:41.252437Z",
     "start_time": "2025-04-09T16:29:36.469471Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install lightgbm",
   "id": "1e1367fd46489819",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\shoun\\miniconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\shoun\\miniconda3\\lib\\site-packages (from lightgbm) (1.14.1)\n",
      "Downloading lightgbm-4.6.0-py3-none-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 15.2 MB/s eta 0:00:00\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.6.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-09T16:29:59.248745Z",
     "start_time": "2025-04-09T16:29:41.367652Z"
    }
   },
   "source": [
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv('./data/Processed_Combined_IoT_dataset.csv')\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "print(\"Dataset shape:\", dataset.shape)\n",
    "print(\"Columns:\", list(dataset.columns))\n",
    "\n",
    "target_cols = dataset.columns[-1:].tolist()\n",
    "feature_cols = dataset.columns[:-1].tolist()\n",
    "\n",
    "# Split Dataset into Features and Target\n",
    "X = dataset.drop('label', axis=1)\n",
    "y = dataset['label']\n",
    "\n",
    "print(\"X head:\\n\", X.head())\n",
    "print(\"y head:\\n\", y.head())\n",
    "\n",
    "# Splitting Data into Training and Test Sets (70% train, 30% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Building and Evaluating Model with Single Split (LightGBM)\n",
    "start = timeit.default_timer()\n",
    "clf = LGBMClassifier(n_estimators=100, random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = timeit.default_timer() - start\n",
    "\n",
    "start = timeit.default_timer()\n",
    "y_pred = clf.predict(X_test)\n",
    "test_time = timeit.default_timer() - start\n",
    "\n",
    "print(\"\\nSingle Split Evaluation (LightGBM):\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", metrics.f1_score(y_test, y_pred))\n",
    "print(\"Mean Absolute Error:\", metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"Cohen's Kappa:\", metrics.cohen_kappa_score(y_test, y_pred))\n",
    "print(\"ROC AUC:\", metrics.roc_auc_score(y_test, y_pred))\n",
    "print(\"Train Time (s):\", train_time)\n",
    "print(\"Test Time (s):\", test_time)\n",
    "\n",
    "# K-Fold Cross-Validation (LightGBM)\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "train_times = []\n",
    "test_times = []\n",
    "\n",
    "print(f\"\\nStarting {k}-Fold Cross-Validation with LightGBM...\")\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X), 1):\n",
    "    X_train_kf, X_val_kf = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_kf, y_val_kf = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Train the model\n",
    "    start = timeit.default_timer()\n",
    "    clf_kf = LGBMClassifier(n_estimators=100, random_state=1)\n",
    "    clf_kf.fit(X_train_kf, y_train_kf)\n",
    "    train_times.append(timeit.default_timer() - start)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    start = timeit.default_timer()\n",
    "    y_pred_kf = clf_kf.predict(X_val_kf)\n",
    "    test_times.append(timeit.default_timer() - start)\n",
    "\n",
    "    # Store metrics\n",
    "    accuracy_scores.append(metrics.accuracy_score(y_val_kf, y_pred_kf))\n",
    "    precision_scores.append(metrics.precision_score(y_val_kf, y_pred_kf))\n",
    "    recall_scores.append(metrics.recall_score(y_val_kf, y_pred_kf))\n",
    "    f1_scores.append(metrics.f1_score(y_val_kf, y_pred_kf))\n",
    "\n",
    "    print(f\"Fold {fold} - Accuracy: {accuracy_scores[-1]:.4f}, \"\n",
    "          f\"Precision: {precision_scores[-1]:.4f}, \"\n",
    "          f\"Recall: {recall_scores[-1]:.4f}, \"\n",
    "          f\"F1 Score: {f1_scores[-1]:.4f}\")\n",
    "\n",
    "# Summary of K-Fold Results\n",
    "print(f\"\\n{k}-Fold Cross-Validation Summary (LightGBM):\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_scores):.4f} (±{np.std(accuracy_scores):.4f})\")\n",
    "print(f\"Average Precision: {np.mean(precision_scores):.4f} (±{np.std(precision_scores):.4f})\")\n",
    "print(f\"Average Recall: {np.mean(recall_scores):.4f} (±{np.std(recall_scores):.4f})\")\n",
    "print(f\"Average F1 Score: {np.mean(f1_scores):.4f} (±{np.std(f1_scores):.4f})\")\n",
    "print(f\"Average Train Time (s): {np.mean(train_times):.4f}\")\n",
    "print(f\"Average Test Time (s): {np.mean(test_times):.4f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (401119, 18)\n",
      "Columns: ['FC1_Read_Input_Register', 'FC2_Read_Discrete_Value', 'FC3_Read_Holding_Register', 'FC4_Read_Coil', 'current_temperature', 'door_state', 'fridge_temperature', 'humidity', 'latitude', 'light_status', 'longitude', 'motion_status', 'pressure', 'sphone_signal', 'temp_condition', 'temperature', 'thermostat_status', 'label']\n",
      "X head:\n",
      "    FC1_Read_Input_Register  FC2_Read_Discrete_Value  \\\n",
      "0                 0.495216                 0.499092   \n",
      "1                 0.495216                 0.499092   \n",
      "2                 0.495216                 0.499092   \n",
      "3                 0.495216                 0.499092   \n",
      "4                 0.495216                 0.499092   \n",
      "\n",
      "   FC3_Read_Holding_Register  FC4_Read_Coil  current_temperature  door_state  \\\n",
      "0                   0.488897       0.499405             0.344399           0   \n",
      "1                   0.488897       0.499405             0.344399           0   \n",
      "2                   0.488897       0.499405             0.344399           0   \n",
      "3                   0.488897       0.499405             0.344399           0   \n",
      "4                   0.488897       0.499405             0.344399           0   \n",
      "\n",
      "   fridge_temperature  humidity  latitude  light_status  longitude  \\\n",
      "0            0.930769  0.462511  0.008217             0   0.008112   \n",
      "1            0.588462  0.462511  0.008217             0   0.008112   \n",
      "2            0.076923  0.462511  0.008217             0   0.008112   \n",
      "3            0.292308  0.462511  0.008217             0   0.008112   \n",
      "4            0.746154  0.462511  0.008217             0   0.008112   \n",
      "\n",
      "   motion_status  pressure  sphone_signal  temp_condition  temperature  \\\n",
      "0              0  0.533556       0.666667             0.2     0.517307   \n",
      "1              0  0.533556       0.666667             0.2     0.517307   \n",
      "2              0  0.533556       0.666667             0.8     0.517307   \n",
      "3              0  0.533556       0.666667             0.8     0.517307   \n",
      "4              0  0.533556       0.666667             0.2     0.517307   \n",
      "\n",
      "   thermostat_status  \n",
      "0                  1  \n",
      "1                  1  \n",
      "2                  1  \n",
      "3                  1  \n",
      "4                  1  \n",
      "y head:\n",
      " 0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: label, dtype: int64\n",
      "X_train shape: (280783, 17)\n",
      "X_test shape: (120336, 17)\n",
      "y_train shape: (280783,)\n",
      "y_test shape: (120336,)\n",
      "[LightGBM] [Info] Number of positive: 109278, number of negative: 171505\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2719\n",
      "[LightGBM] [Info] Number of data points in the train set: 280783, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389190 -> initscore=-0.450717\n",
      "[LightGBM] [Info] Start training from score -0.450717\n",
      "\n",
      "Single Split Evaluation (LightGBM):\n",
      "Confusion Matrix:\n",
      " [[71582  1913]\n",
      " [19760 27081]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.87     73495\n",
      "           1       0.93      0.58      0.71     46841\n",
      "\n",
      "    accuracy                           0.82    120336\n",
      "   macro avg       0.86      0.78      0.79    120336\n",
      "weighted avg       0.84      0.82      0.81    120336\n",
      "\n",
      "Accuracy: 0.8198959579843106\n",
      "Precision: 0.9340208318962544\n",
      "Recall: 0.5781473495442028\n",
      "F1 Score: 0.7142084789345289\n",
      "Mean Absolute Error: 0.18010404201568941\n",
      "Cohen's Kappa: 0.5930951694715736\n",
      "ROC AUC: 0.7760591839904156\n",
      "Train Time (s): 2.23497619999398\n",
      "Test Time (s): 0.2741502999997465\n",
      "\n",
      "Starting 5-Fold Cross-Validation with LightGBM...\n",
      "[LightGBM] [Info] Number of positive: 124855, number of negative: 196040\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2719\n",
      "[LightGBM] [Info] Number of data points in the train set: 320895, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389084 -> initscore=-0.451166\n",
      "[LightGBM] [Info] Start training from score -0.451166\n",
      "Fold 1 - Accuracy: 0.8205, Precision: 0.9353, Recall: 0.5795, F1 Score: 0.7157\n",
      "[LightGBM] [Info] Number of positive: 125013, number of negative: 195882\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2719\n",
      "[LightGBM] [Info] Number of data points in the train set: 320895, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389576 -> initscore=-0.449095\n",
      "[LightGBM] [Info] Start training from score -0.449095\n",
      "Fold 2 - Accuracy: 0.8179, Precision: 0.9311, Recall: 0.5728, F1 Score: 0.7093\n",
      "[LightGBM] [Info] Number of positive: 125004, number of negative: 195891\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2719\n",
      "[LightGBM] [Info] Number of data points in the train set: 320895, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389548 -> initscore=-0.449213\n",
      "[LightGBM] [Info] Start training from score -0.449213\n",
      "Fold 3 - Accuracy: 0.8204, Precision: 0.9343, Recall: 0.5776, F1 Score: 0.7139\n",
      "[LightGBM] [Info] Number of positive: 124676, number of negative: 196219\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2719\n",
      "[LightGBM] [Info] Number of data points in the train set: 320895, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.388526 -> initscore=-0.453513\n",
      "[LightGBM] [Info] Start training from score -0.453513\n",
      "Fold 4 - Accuracy: 0.8192, Precision: 0.9375, Recall: 0.5772, F1 Score: 0.7145\n",
      "[LightGBM] [Info] Number of positive: 124928, number of negative: 195968\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2719\n",
      "[LightGBM] [Info] Number of data points in the train set: 320896, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.389310 -> initscore=-0.450214\n",
      "[LightGBM] [Info] Start training from score -0.450214\n",
      "Fold 5 - Accuracy: 0.8205, Precision: 0.9329, Recall: 0.5799, F1 Score: 0.7152\n",
      "\n",
      "5-Fold Cross-Validation Summary (LightGBM):\n",
      "Average Accuracy: 0.8197 (±0.0010)\n",
      "Average Precision: 0.9342 (±0.0022)\n",
      "Average Recall: 0.5774 (±0.0025)\n",
      "Average F1 Score: 0.7137 (±0.0023)\n",
      "Average Train Time (s): 1.6793\n",
      "Average Test Time (s): 0.1764\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
